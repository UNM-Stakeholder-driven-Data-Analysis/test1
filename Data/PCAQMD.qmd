---
title: "Untitled"
format: html
server: shiny
---

## Shiny Documents

This Quarto document is made interactive using Shiny. Interactive documents allow readers to modify parameters and see the results immediately. Learn more about Shiny interactive documents at <https://quarto.org/docs/interactive/shiny/>.

## Inputs and Outputs

You can embed Shiny inputs and outputs in your document. Outputs are automatically updated whenever inputs change. This demonstrates how a standard R plot can be made interactive:

```{r}
sliderInput("bins", "Number of bins:", 
            min = 1, max = 50, value = 30)
plotOutput("distPlot")
```

```{r}
#| context: server
output$distPlot <- renderPlot({
   x <- faithful[, 2]  # Old Faithful Geyser data
   bins <- seq(min(x), max(x), length.out = input$bins + 1)
   hist(x, breaks = bins, col = 'darkgray', border = 'white',
        xlab = 'Waiting time to next eruption (in mins)',
        main = 'Histogram of waiting times')
})
```


#### read me ####

# The purpose of this script is to demonstrate calculating and exploring a PCA on a stream chemistry dataset

# Steps:
# 1. Check that data meets assumptions of PCAs
# 2. Compute PCA
# 3. Explore PCA
# 4. Plot PCA
# 5. Check that results meet assumptions - outliers
# 6. (actually 1!) Decide which axes to retain
# 7. Interpret axes
# 8. Extract scores for further analysis (if applicable)

#### libraries ####

library(tidyverse)
library(ade4)
library(psych)
library(FactoMineR)
library(factoextra)
library(corrplot)

#### load and tidy data ####
setwd("C:/Users/marag.DESKTOP-NEKBNJE/OneDrive/Desktop/Stakeholder data analysis/test1/Data")
dat = read.csv("anionsf.csv")
dat <- read.csv("anionsf.csv", na.strings = c("."))
str(dat)
#dat<- na.omit(dat)

# reduce to 3 sites for the purposes of most of this tutorial
#dat = dat[dat$SiteName =="Savannah"| dat$Site.Name =="Calabacillas"| dat$Site.Name =="Minnow",]

# check data classes 
str(dat)

# format date/time

# format date/time: this code worked well to format date
dat$DateF = as.POSIXct(dat$Date, format="%m/%d/%Y %H:%M", tz="US/Mountain")
str(dat)
#dat$datetime_NM = as.POSIXct(dat$Sample_DateTime, format="%m/%d/%y %H:%M", tz="US/Mountain")

# convert characters that should be factors (categories) to factors
dat$SiteName = as.factor(dat$SiteName)
dat$Samplingtype = as.factor(dat$Samplingtype)
#dat$Is_Nondetect = as.factor(dat$Is_Nondetect)

# convert water quality data to numeric
dat$Bromide = as.numeric(dat$Bromide)
dat$Fluoride = as.numeric(dat$Fluoride)
dat$NH4N  = as.numeric(dat$NH4N )
dat$Sulfate = as.numeric(dat$Sulfate)
dat$Chloride = as.numeric(dat$Chloride)
dat$PhosphateP = as.numeric(dat$PhosphateP)
dat$Turbidity = as.numeric(dat$Turbidity)
dat$condTemp = as.numeric(dat$condTemp)
dat$DO  = as.numeric(dat$DO)

#datF <- 
 # dat %>%  subset(dat, select = -c(Year,Month,Day,Sampling.type, Do,Fluoride,Nitrite,Bromide,NitrateN,PhosphateP,NH4.N,DateF, Timesampling, Timeofsitearrival, Date, Datecombined ))

# only keep select columns
#datS <-
 # dat %>%  subset(dat, select = -c("Airtemp", "Turbidity", "DoPercent", "DOTemp", "Conductivity", "condTemp" ,"pH1" , "Chloride", "Sulfate"))

datS <- select(dat, c("SiteName","Airtemp", "DoPercent", "DOTemp", "Conductivity", "condTemp" ,"pH1" , "Chloride", "Sulfate"))
str(datS)
#


#dat = dat %>% 
 # rownames_to_column("Site.Name") %>% 
 # separate(Site, c("Year","Day","Month","Sampling.type","Time","DO","Fluoride","Nitrite","Bromide","NitrateN", "PhosphateP", "NH4.N ", "DateF "), remove = F)
# turn columns and variables to numeric and factor


#exclude variables and work on non zero inflated variables (Will have ~ 9 variables not zero inflated)


#### 1. check assumption ####

datS<- na.omit(datS)

pairs.panels(datS[,2:9], scale=TRUE)

range(datS$Sulfate)
range(datS$Chloride)
range(datS$condTemp)

#### 2. compute PCA ####

d2 = datS[,2:9]
rownames(d2) = datS$SiteName

pca = prcomp(d2, scale = T)

summary(pca)

str(pca)

# The value of each observation on each PC axis
# also known as "scores"
pca$x 

#### 3. explore PCA ####

### view eigenvalues: ##
get_eigenvalue(pca) 
fviz_eig(pca, addlabels = TRUE, choice = c("eigenvalue")) # as scree plot with eigenvalues
fviz_eig(pca, addlabels = TRUE, choice = c("variance")) # as scree plot with % variance explained

#### 4. plot pca ####

# biplot of sites + variables #
pca.p.1.2 = 
  fviz_pca_biplot(pca, 
                  axes = c(1, 2), # specify axes
                  repel = TRUE,
                  col.var = "blue", # Variables color
                  col.ind = "#696969"  # Individuals color
  )

pca.p.1.3 =
  fviz_pca_biplot(pca, 
                  axes = c(1, 3), # specify axes
                  repel = TRUE,
                  col.var = "#2E9FDF", # Variables color
                  col.ind = "#696969"  # Individuals color
  )

pca.p.1.4 =
  fviz_pca_biplot(pca, 
                  axes = c(1, 4), # specify axes
                  repel = TRUE,
                  col.var = "#2E9FDF", # Variables color
                  col.ind = "#696969"  # Individuals color
  )

# plot of sites + 95% CI groupings #

fviz_pca_ind(pca, habillage=datS$SiteName, 
             axes = c(1, 2),
             label="none", 
             addEllipses=TRUE, ellipse.level=0.95)

fviz_pca_ind(pca, habillage=datS$SiteName, 
             axes = c(1, 3),
             label="none", 
             addEllipses=TRUE, ellipse.level=0.95)

fviz_pca_ind(pca, habillage=datS$SiteName, 
             axes = c(2, 3),
             label="none", 
             addEllipses=TRUE, ellipse.level=0.95)

fviz_pca_ind(pca, habillage=datS$site_group, 
             axes = c(1, 4),
             label="none", 
             addEllipses=TRUE, ellipse.level=0.95)

fviz_pca_ind(pca, habillage=datS$site_group, 
             axes = c(1, 5),
             label="none", 
             addEllipses=TRUE, ellipse.level=0.95)

fviz_pca_ind(pca, habillage=datS$site_group, 
             axes = c(1, 6),
             label="none", 
             addEllipses=TRUE, ellipse.level=0.95)


#### 5. check weight of outliers ####

# specify outliers #
outliers = c("au_2")

# remove outliers #
d3 = d2[!(row.names(d2) %in% outliers),]

# re-compute pca #
pca2 = prcomp(d3, scale = T)

# re-plot pca #
fviz_pca_biplot(pca2, 
                axes = c(1, 2), # specify axes
                repel = TRUE,
                col.var = "blue", # Variables color
                col.ind = "#696969"  # Individuals color
)
# looks similar, so can use unaltered d #

#### 6. (actually 1!) decide which axes to retain ####

### YOU SHOULD CHOOSE WHICH RULE TO FOLLOW A-PRIORI!!! ###
# Possible a priori rules:
# a)  1 eigenvalue rule: values of 1 indicate that those axes account for more variance than any one original variable (standardized data only). Rule is to retain all axes with an eigenvalue of 1 or more
# b) % total variance rule: retain all axes for which % variance explained sums to > X% (e.g., 90%)
# c) % variance rule: retain all axes for which at least X% variance is explained (e.g., 10%)
# d) Broken stick rule: retain all axes before break in scree plot



fviz_eig(pca, addlabels = TRUE, choice = c("eigenvalue")) # as scree plot with eigenvalues
fviz_eig(pca, addlabels = TRUE, choice = c("variance")) # as scree plot with % variance explained

#### 7. interpret axes ####

# extract results
var = get_pca_var(pca)

# extract contribution of each variable to each PC (unit = %) #
contrib = (var$contrib)
contrib

# plot contribution #

corrplot(contrib, is.corr = F)

# axis 1:

# axis 2:

# axis 3:


#### 8. extract scores ####

pca.scrs = as.data.frame(pca$x[,1:3])
pca.scrs

